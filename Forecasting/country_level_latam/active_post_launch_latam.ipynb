{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f95f804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "import os\n",
    "import io\n",
    "import logging\n",
    "\n",
    "import boto3\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6d21e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8922493",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092955e8",
   "metadata": {},
   "source": [
    "# 1. Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041765a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_bucket = 'hbo-ingest-datascience-content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad9c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.info(f'Loading inputs')\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(input_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0659217",
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in bucket.objects.filter(Prefix='pct_actives_prediction_latam/pct_actives_metric_values_latam'):\n",
    "    key = obj.key\n",
    "    logger.info('Loading csv file {}'.format(key))\n",
    "    body = obj.get()['Body']\n",
    "    var_name = key.split('.')[0].split('/')[1]\n",
    "    print('Reading {0} features'.format(var_name))\n",
    "\n",
    "    pct_actives = pd.read_csv(body, na_values = [r'\\\\\\\\N'])\n",
    "    pct_actives.columns = pct_actives.columns.str.lower()\n",
    "    pct_actives= pct_actives.loc[pct_actives['match_id'].\\\n",
    "                isin(['1-GYGQBcwsaCIW2XgEAAAAL', '0-GYGQBcwsaCIW2XgEAAAAL', '1-GYEb9QwLgFF9_ZwEAAAA7', '0-GYEb9QwLgFF9_ZwEAAAA7'])==False,:]\\\n",
    "                .reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95c92a7",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48e6c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecayModel:\n",
    "    def __init__(self, kpi):\n",
    "        self.tracking_col = TRACKING_COLUMN[kpi]\n",
    "        self.multiplier_df = None\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        pct_actives = train_df\n",
    "        pct_actives_from = pct_actives[['originals_type', 'content_category',\n",
    "                                    'match_id','prediction_start_day', 'territory', self.tracking_col]]\n",
    "        pct_actives_from.rename(columns={self.tracking_col: self.tracking_col + '_from'}, inplace=True)\n",
    "\n",
    "\n",
    "        pct_actives_to = pct_actives[['originals_type', 'content_category',\n",
    "                                        'match_id','prediction_start_day', 'territory', self.tracking_col]]\n",
    "        pct_actives_to.rename(columns={self.tracking_col: self.tracking_col + '_to',\n",
    "                                         'prediction_start_day': 'days_after_launch'}, inplace=True)\n",
    "\n",
    "\n",
    "        multipliers = pd.merge(pct_actives_from, pct_actives_to,\n",
    "                           on=['originals_type', 'content_category',\n",
    "                               'match_id', 'territory'])\n",
    "        multipliers['multiplier'] = multipliers[self.tracking_col + '_to'] / multipliers[self.tracking_col+ '_from']\n",
    "        multiplier_df = multipliers.groupby(['originals_type', 'content_category', 'territory',\n",
    "                                             'prediction_start_day', 'days_after_launch'],\n",
    "                                            as_index=False).agg({'multiplier': 'median'})\n",
    "        self.multiplier_df = multiplier_df\n",
    "\n",
    "    def predict(self, pred_df):\n",
    "\n",
    "        postlaunch_df = pred_df[META_COLUMNS + [self.tracking_col]]\n",
    "\n",
    "        assert self.tracking_col in postlaunch_df.columns\n",
    "\n",
    "\n",
    "        postlaunch_df = pd.merge(postlaunch_df, self.multiplier_df,\n",
    "                                 on=['originals_type', 'content_category', 'prediction_start_day', 'territory'],\n",
    "                                 how='left')\n",
    "\n",
    "        postlaunch_prediction = np.where(postlaunch_df['prediction_start_day'] > postlaunch_df['days_after_launch'],\n",
    "                                         np.nan,\n",
    "                                         postlaunch_df[self.tracking_col] * postlaunch_df['multiplier'])\n",
    "\n",
    "        postlaunch_df['prediction'] = postlaunch_prediction\n",
    "\n",
    "\n",
    "        postlaunch_df = postlaunch_df[META_COLUMNS + ['days_after_launch', 'prediction']]\n",
    "\n",
    "        return postlaunch_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0026548",
   "metadata": {},
   "source": [
    "# 3. Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0feb0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "META_COLUMNS = ['match_id',\n",
    "                'title',\n",
    "                'available_date',\n",
    "                'originals_type',\n",
    "                'content_category',\n",
    "                'real_date',\n",
    "                'prediction_start_day',\n",
    "                'territory'\n",
    "                ]\n",
    "TRACKING_COLUMN = {'pct_actives': 'pct_actives',\n",
    "                 'total_actives': 'total_viewing_accounts',\n",
    "                 'title_actives': 'title_viewing_accounts',\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e290f679",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi = 'pct_actives'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd9344",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger_titles = pct_actives[(pct_actives['days_on_hbo_max'] == 28)\n",
    "                       &(pct_actives['pct_actives'] > 1)]\n",
    "\n",
    "data_train_all = pct_actives[(pct_actives['prod_release_year'] >= 2021)\n",
    "                            &(pct_actives.match_id.isin(bigger_titles.match_id))].copy()\n",
    "\n",
    "data_train_all.rename(columns={\"days_on_hbo_max\": \"prediction_start_day\"}, inplace=True)\n",
    "data_train_all['real_date'] = data_train_all['real_date'].map(str).map(lambda x: x[:10])\n",
    "data_train_all['available_date'] = data_train_all['available_date'].map(str).map(lambda x: x[:10])\n",
    "data_train_all['match_id_territory'] = data_train_all['match_id'] + '_' +  data_train_all['territory']\n",
    "\n",
    "# logger.info(\"nrow(features): \" + str(len(data_train_all.index)))\n",
    "print(\"nrow(features): \" + str(len(data_train_all.index)))\n",
    "\n",
    "validation_set = pd.DataFrame()\n",
    "\n",
    "num_folds = len(data_train_all['match_id_territory'].unique())\n",
    "group_kfold = GroupKFold(n_splits=num_folds)\n",
    "print (group_kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520e70dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in group_kfold.split(data_train_all, groups=data_train_all['match_id_territory'].values):\n",
    "\n",
    "\n",
    "    train_df, test_df = data_train_all.iloc[train_index], data_train_all.iloc[test_index]\n",
    "    train_df = train_df[train_df['territory'] == str(test_df['territory'].values[0])]\n",
    "\n",
    "\n",
    "    avail_date = test_df['available_date'].values[0]\n",
    "    train_df = train_df[(train_df['available_date'] <= avail_date)]\n",
    "\n",
    "    print(\"Validation Title: \" + str(test_df['title'].values[0]) + ' at ' + str(test_df['territory'].values[0]))\n",
    "\n",
    "    # fit_predict decay model\n",
    "    decay_model = DecayModel(kpi=kpi)\n",
    "    decay_model.fit(train_df)\n",
    "    pred = decay_model.predict(test_df)\n",
    "    validation_set = pd.concat((validation_set, pred))\n",
    "\n",
    "validation_set = validation_set[validation_set['days_after_launch'].notnull()]\n",
    "validation_set.reset_index(drop=True, inplace=True)\n",
    "# post-process\n",
    "validation_set.rename(columns={'real_date': 'prediction_start_date'}, inplace=True)\n",
    "validation_set['real_date'] = pd.to_datetime(validation_set['available_date']\n",
    "                                            ).add(\n",
    "    validation_set['days_after_launch'].map(lambda x: datetime.timedelta(x))\n",
    "    ).map(str).map(lambda x: x[:10])\n",
    "\n",
    "validation_set = pd.merge(validation_set,\n",
    "                          data_train_all[\n",
    "                              ['match_id', 'real_date', 'season_number', 'territory'] + [TRACKING_COLUMN[kpi]]],\n",
    "                          on=['match_id', 'real_date', 'territory'],\n",
    "                          how='left')\n",
    "\n",
    "validation_set.rename(columns={TRACKING_COLUMN[kpi]: 'actuals'}, inplace=True)\n",
    "\n",
    "validation_set = validation_set[['match_id',\n",
    "                                 'title',\n",
    "                                 'territory',\n",
    "                                 'available_date',\n",
    "                                 'originals_type',\n",
    "                                 'content_category',\n",
    "                                 'prediction_start_date',\n",
    "                                 'real_date',\n",
    "                                 'prediction_start_day',\n",
    "                                 'days_after_launch',\n",
    "                                 'actuals',\n",
    "                                 'prediction']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184ccceb",
   "metadata": {},
   "source": [
    "# 4. Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef9b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_df = pct_actives.copy()\n",
    "scoring_df['max_days'] = scoring_df.groupby(['match_id'])['days_on_hbo_max'].transform(max)\n",
    "scoring_df.rename(columns={\"days_on_hbo_max\": \"prediction_start_day\"}, inplace=True)\n",
    "scoring_df['real_date'] = scoring_df['real_date'].map(str).map(lambda x: x[:10])\n",
    "scoring_df['available_date'] = scoring_df['available_date'].map(str).map(lambda x: x[:10])\n",
    "scoring_df['match_id_territory'] = scoring_df['match_id'] + '_' +  pct_actives['territory']\n",
    "\n",
    "train_df = scoring_df[(scoring_df['available_date'] < (pd.to_datetime(\"now\") - timedelta(days=28)).strftime('%Y-%m-%d'))\n",
    "                      &(scoring_df.match_id.isin(bigger_titles.match_id))]\n",
    "test_df = scoring_df[scoring_df['available_date'] >= (pd.to_datetime(\"now\") - timedelta(days=28)).strftime('%Y-%m-%d')]\n",
    "\n",
    "kpi = 'pct_actives'\n",
    "\n",
    "print(\"nrow(features): \" + str(len(test_df.index)))\n",
    "\n",
    "pred_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652fb3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id, feature in test_df.groupby('match_id_territory'):\n",
    "\n",
    "    print(\"Scoring Title: \" + str(feature['title'].values[0]) + ' at ' + str(feature['territory'].values[0]))\n",
    "    avail_date = feature['available_date'].values[0]\n",
    "    train_features = train_df[(train_df['available_date'] <= avail_date)\n",
    "                             &(train_df['territory'] == str(feature['territory'].values[0]))]\n",
    "\n",
    "    # fit_predict decay model\n",
    "    decay_model = DecayModel(kpi=kpi)\n",
    "    decay_model.fit(train_features)\n",
    "    pred = decay_model.predict(feature)\n",
    "    pred_df = pd.concat((pred_df, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56982a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df[pred_df['days_after_launch'].notnull()]\n",
    "pred_df.reset_index(drop=True, inplace=True)\n",
    "# post-process\n",
    "pred_df.rename(columns={'real_date': 'prediction_start_date'}, inplace=True)\n",
    "pred_df['real_date'] = pd.to_datetime(pred_df['available_date']\n",
    "                                    ).add(pred_df['days_after_launch'].map(lambda x: datetime.timedelta(x))\n",
    "                                    ).map(str).map(lambda x: x[:10])\n",
    "\n",
    "pred_df = pred_df[['match_id',\n",
    "                                 'title',\n",
    "                                 'territory',\n",
    "                                 'available_date',\n",
    "                                 'originals_type',\n",
    "                                 'content_category',\n",
    "                                 'prediction_start_date',\n",
    "                                 'real_date',\n",
    "                                 'prediction_start_day',\n",
    "                                 'days_after_launch',\n",
    "                                 'prediction']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d850a66",
   "metadata": {},
   "source": [
    "# 5. Ouput Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6898914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'pct_actives_latam_cv_results'\n",
    "filename ='pct_actives_prediction_latam/' + table_name + '.csv'\n",
    "csv_buffer = io.StringIO()\n",
    "validation_set.to_csv(csv_buffer, index = False)\n",
    "content = csv_buffer.getvalue()\n",
    "client = boto3.client('s3')\n",
    "client.put_object(Bucket=output_bucket, Key=filename, Body=content)\n",
    "print ('Write cv to S3 finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c25af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'pct_actives_latam_scoring_results'\n",
    "filename ='pct_actives_prediction_latam/' + table_name + '.csv'\n",
    "csv_buffer = io.StringIO()\n",
    "pred_df.to_csv(csv_buffer, index = False)\n",
    "content = csv_buffer.getvalue()\n",
    "client = boto3.client('s3')\n",
    "client.put_object(Bucket=output_bucket, Key=filename, Body=content)\n",
    "print ('Write scoring to S3 finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c943117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
