{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35862391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import datetime as dt\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37903820",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c78689bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "class Credentials(metaclass=ABCMeta):\n",
    "    pass\n",
    "    \n",
    "    \n",
    "class SSMPSCredentials(Credentials):\n",
    "    def __init__(self, secretid: str):\n",
    "        self._secretid = secretid\n",
    "        self._secrets = {}\n",
    "        \n",
    "    def get_keys(self):\n",
    "        \"\"\"\n",
    "        credential fetching \n",
    "        \"\"\"\n",
    "        _aws_sm_args = {'service_name': 'secretsmanager', 'region_name': 'us-east-1'}\n",
    "        secrets_client = boto3.client(**_aws_sm_args)\n",
    "        get_secret_value_response = secrets_client.get_secret_value(SecretId=self._secretid)\n",
    "        return get_secret_value_response\n",
    "    \n",
    "    \n",
    "class BaseConnector(metaclass=ABCMeta):\n",
    "    @abstractmethod\n",
    "    def connect(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "\n",
    "class SnowflakeConnector(BaseConnector):\n",
    "    def __init__(self, credentials: Credentials):\n",
    "        keys = credentials.get_keys()\n",
    "        self._secrets = json.loads(keys.get('SecretString', \"{}\"))\n",
    "\n",
    "    def connect(self, dbname: str, schema: str = 'DEFAULT'):\n",
    "        ctx = snowflake.connector.connect(\n",
    "            user=self._secrets['login_name'],\n",
    "            password=self._secrets['login_password'],\n",
    "            account=self._secrets['account'],\n",
    "            warehouse=self._secrets['warehouse'],\n",
    "            database=dbname,\n",
    "            schema=schema\n",
    "        )\n",
    "\n",
    "        return ctx\n",
    "    \n",
    "## Credentials\n",
    "SF_CREDS = 'datascience-max-dev-sagemaker-notebooks'\n",
    "\n",
    "## Snowflake connection \n",
    "conn=SnowflakeConnector(SSMPSCredentials(SF_CREDS))\n",
    "ctx=conn.connect(\"MAX_DEV\",\"WORKSPACE\")\n",
    "\n",
    "def run_query(query):\n",
    "    cursor = ctx.cursor()\n",
    "    cursor.execute(query)\n",
    "    df = pd.DataFrame(cursor.fetchall(), columns = [desc[0] for desc in cursor.description])\n",
    "    df.columns= df.columns.str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182c3b3f",
   "metadata": {},
   "source": [
    "# Retail Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "771defc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_info = run_query('''\n",
    "with offerings as (select DISTINCT\n",
    "            case when season_number is not null then concat(title_name, ' S', season_number, ('E'), EPISODE_NUMBER_IN_SEASON)\n",
    "            else title_name end as title_episode_name\n",
    "    , title_name\n",
    "    , rad.VIEWABLE_ID\n",
    "    , concat(coalesce(rad.series_id, rad.viewable_id)) as title_id\n",
    "    , rad.SERIES_ID\n",
    "    , rad.SEASON_NUMBER\n",
    "    , EPISODE_NUMBER_IN_SEASON\n",
    "    , content_category\n",
    "    , PRIMARY_GENRE_DESC\n",
    "    , program_type\n",
    "    , aod.air_date\n",
    "    , ASSET_RUN_TIME\n",
    "    , offering_start_date\n",
    "    , offering_end_date\n",
    "     FROM \"MAX_PROD\".\"CATALOG\".\"ASSET_OFFERING_DIM\" aod\n",
    "LEFT JOIN \"MAX_PROD\".\"CATALOG\".\"REPORTING_ASSET_DIM\" rad ON aod.VIEWABLE_ID = rad.VIEWABLE_ID\n",
    "where territory='HBO MAX DOMESTIC'\n",
    "    and channel = 'HBO MAX SUBSCRIPTION'\n",
    "    and OFFERING_TYPE = 'FEATURE')\n",
    "\n",
    ", airtable as (\n",
    "    select DISTINCT title_id \n",
    "    , MIN(PILLAR_GENRE) as PILLAR_GENRE -- multiple PILLAR GENRE assignments for a single VIEWABLE_ID, taking at random.\n",
    "    from max_prod.catalog.airtable_content_strategy group by title_id)\n",
    "\n",
    ", pay1 as (\n",
    "    SELECT DISTINCT viewable_id, is_pay_1\n",
    "    FROM max_prod.staging.tentpole_titles_stg stg\n",
    "    WHERE stg.territory = 'HBO MAX DOMESTIC'\n",
    "    and stg.theatrical_release_date is not null\n",
    "    and stg.is_pay_1 =1\n",
    ")\n",
    "\n",
    ", budget as (\n",
    "    SELECT DISTINCT map.viewable_id, bdg.AMOUNT as budget\n",
    "    FROM \"MAX_PROD\".\"CKG\".IMDB_BOXOFFICE_TITLE_BUDGET bdg\n",
    "    JOIN max_prod.ckg.ed_wm_wb_imdb_mapping map --vid to imdb_id\n",
    "    ON map.imdb_id=bdg.title_id\n",
    ")\n",
    "\n",
    ",offerings_by_date as (\n",
    "select\n",
    "     TITLE_NAME, title_episode_name\n",
    "    , offerings.VIEWABLE_ID\n",
    "    , offerings.title_id, offerings.SEASON_NUMBER\n",
    "    , CONTENT_CATEGORY, program_type, air_date\n",
    "    , am.home_territory_observed_medal as medal\n",
    "    , CAST(FLOOR(COALESCE( (ASSET_RUN_TIME)/60/60 ,0)*(1000000*1.0)) AS DECIMAL(38,0))\n",
    "          / CAST((1000000*1.0) AS DOUBLE PRECISION) as ASSET_RUN_TIME_HOURS -- to prevent floating point errors\n",
    "    , case when to_date(offerings.offering_start_date) < '2020-05-27' THEN to_date('2020-05-27')\n",
    "           ELSE to_date(offerings.offering_start_date)\n",
    "           end as offering_start_date\n",
    "    , to_date(offerings.offering_end_date) as offering_end_date\n",
    "    , PRIMARY_GENRE_DESC\n",
    "    , aos.PILLAR_GENRE as PILLAR_GENRE\n",
    "    , EPISODE_NUMBER_IN_SEASON\n",
    "    , CASE WHEN pay1.is_pay_1 IS NOT NULL THEN 1 ELSE 0 END AS is_pay_1\n",
    "    , CASE WHEN pop.THEATRICAL_RELEASE_DATE IS NOT NULL THEN 1 ELSE 0 END AS is_popcorn\n",
    "    , MAX(budget) AS budget \n",
    "FROM offerings\n",
    "LEFT JOIN airtable aos ON (offerings.title_id = aos.title_id)\n",
    "LEFT JOIN max_prod.content_analytics.asset_medals am \n",
    "        on offerings.title_id = am.title_id\n",
    "        and coalesce(offerings.season_number,0) = coalesce(am.season,0)\n",
    "LEFT JOIN pay1\n",
    "        on pay1.viewable_id = offerings.viewable_id\n",
    "LEFT JOIN max_prod.catalog.popcorn_titles pop \n",
    "        on pop.viewable_id = offerings.viewable_id\n",
    "LEFT JOIN budget\n",
    "        on budget.viewable_id = offerings.viewable_id\n",
    "WHERE 1=1\n",
    "-- offerings.OFFERING_START_DATE > '2020-05-01'\n",
    "-- and CURRENT_DATE() between (OFFERING_START_DATE) and (OFFERING_END_DATE)\n",
    "GROUP BY 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17\n",
    ")\n",
    "\n",
    "SELECT * FROM offerings_by_date\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c62b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DE-DUPTE THE TITLES\n",
    "\n",
    "title_test_dedup = title_info.groupby(['viewable_id'])['offering_start_date'].min().reset_index()\n",
    "title_info = title_info.merge(title_test_dedup, on = ['viewable_id', 'offering_start_date'])\n",
    "\n",
    "title_test_dedup = title_info.groupby(['viewable_id'])['offering_end_date'].max().reset_index()\n",
    "title_info = title_info.merge(title_test_dedup, on = ['viewable_id', 'offering_end_date'])\n",
    "\n",
    "title_info['medal'] = title_info['medal'].fillna('None')\n",
    "title_test_dedup = title_info.groupby(['viewable_id'])['medal'].max().reset_index()\n",
    "title_info = title_info.merge(title_test_dedup, on = ['viewable_id', 'medal'])\n",
    "\n",
    "\n",
    "title_info = title_info.drop_duplicates()\n",
    "title_info['season_number'] = title_info['season_number'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6ebc136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_name                  42527\n",
       "title_episode_name          42527\n",
       "viewable_id                 42527\n",
       "title_id                    42527\n",
       "season_number               42527\n",
       "content_category            42161\n",
       "program_type                42178\n",
       "air_date                    42260\n",
       "medal                       42527\n",
       "asset_run_time_hours        42527\n",
       "offering_start_date         42527\n",
       "offering_end_date           42527\n",
       "primary_genre_desc          41283\n",
       "pillar_genre                37012\n",
       "episode_number_in_season    35491\n",
       "is_pay_1                    42527\n",
       "is_popcorn                  42527\n",
       "budget                       3644\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_info.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6861f311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_name</th>\n",
       "      <th>title_episode_name</th>\n",
       "      <th>title_id</th>\n",
       "      <th>season_number</th>\n",
       "      <th>content_category</th>\n",
       "      <th>program_type</th>\n",
       "      <th>air_date</th>\n",
       "      <th>medal</th>\n",
       "      <th>asset_run_time_hours</th>\n",
       "      <th>offering_start_date</th>\n",
       "      <th>offering_end_date</th>\n",
       "      <th>primary_genre_desc</th>\n",
       "      <th>pillar_genre</th>\n",
       "      <th>episode_number_in_season</th>\n",
       "      <th>is_pay_1</th>\n",
       "      <th>is_popcorn</th>\n",
       "      <th>budget</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viewable_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title_name, title_episode_name, title_id, season_number, content_category, program_type, air_date, medal, asset_run_time_hours, offering_start_date, offering_end_date, primary_genre_desc, pillar_genre, episode_number_in_season, is_pay_1, is_popcorn, budget]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SANITY CHECK\n",
    "title_test = title_info.groupby(['viewable_id']).count()\n",
    "title_test[title_test['title_name'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b2158a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_series_info = title_info.groupby(['title_id', 'season_number'])['offering_start_date'].min().reset_index()\n",
    "\n",
    "title_series_test = title_info.groupby(['title_id', 'season_number'])['asset_run_time_hours'].sum().reset_index()\n",
    "title_series_info = title_series_info.merge(title_series_test, on = ['title_id', 'season_number'])\n",
    "\n",
    "title_series_test = title_info.groupby(['title_id', 'season_number'])[['content_category', 'program_type', 'air_date', 'medal', 'episode_number_in_season',\n",
    "                                                                       'pillar_genre', 'is_pay_1', 'is_popcorn', 'budget']].max().reset_index()\n",
    "title_series_info = title_series_info.merge(title_series_test, on = ['title_id', 'season_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3346fdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_hours_viewed = run_query('''\n",
    "SELECT e.title_name, t.title_id, t.season_number, h.request_date, t.offering_start_date\n",
    ",days_on_hbo_max\n",
    ",SUM(h.hours_viewed) AS daily_hours_viewed\n",
    ",SUM(daily_hours_viewed) OVER (PARTITION BY t.title_id, t.season_number order by DAYS_ON_HBO_MAX) as cumulative_hours_viewed\n",
    ",cumulative_hours_viewed/subs as average_hours_viewed\n",
    "FROM MAX_DEV.WORKSPACE.user_title_hours_watched_test2 h\n",
    "JOIN (SELECT DISTINCT viewable_id, title_id, season_number, title_name FROM\n",
    "    max_dev.workspace.user_title_hours_watched_episodic_info)  e\n",
    "    on h.viewable_id = e.viewable_id\n",
    "JOIN max_dev.workspace.user_title_hours_watched_title_series_info    t\n",
    "    on e.title_id = t.title_id\n",
    "    and e.season_number = t.season_number\n",
    "JOIN max_dev.workspace.user_title_hours_watched_subs s\n",
    "    on t.offering_start_date = s.start_date\n",
    "    and DATEDIFF('DAY', t.offering_start_date::DATE, h.request_date::DATE) = s.days_on_hbo_max\n",
    "WHERE 1=1\n",
    "AND DATEDIFF('DAY', t.offering_start_date::DATE, h.request_date::DATE) >= 0\n",
    "GROUP BY 1,2,3,4,5,6,subs\n",
    "ORDER BY t.TITLE_ID, t.SEASON_NUMBER, DAYS_ON_HBO_MAX\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f29399c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = title_hours_viewed[['title_name', 'title_id', 'season_number', 'days_on_hbo_max', 'cumulative_hours_viewed', 'average_hours_viewed']].merge(\n",
    "       title_series_info, on = ['title_id', 'season_number'])\n",
    "# data = data[data['days_on_hbo_max'] == 60]\n",
    "data['hvr'] = data['cumulative_hours_viewed']/data['asset_run_time_hours']\n",
    "data['ahvr'] = data['average_hours_viewed']/data['asset_run_time_hours']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b25455f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b9af741",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title_season_name'] = data['title_name']\n",
    "data.loc[data['season_number']>0, 'title_season_name'] = data['title_name'] + ' S' + data['season_number'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eac597df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['match_id'] = data['title_id']\n",
    "data.loc[data['season_number']>0, 'match_id'] = data['title_id'] + ' S' + data['season_number'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e761275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b721b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_60 = full_data[(full_data['days_on_hbo_max'] == 60) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "942fdceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_90 = full_data[(full_data['days_on_hbo_max'] == 91)][['match_id', 'ahvr']].rename(columns = {'ahvr':'ahvr_90'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfa03f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_60 = test_60[['title_name', 'title_id', 'season_number', 'match_id', 'offering_start_date', 'ahvr']]\\\n",
    "          .merge(test_90, on = ['match_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "baea377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ever_green_titles = test_60[(test_60['ahvr'] >= 0.015)\n",
    "       &(test_60['ahvr_90'] >= 1.4*test_60['ahvr'])].sort_values(by = ['title_id'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4b3766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ever_green_titles.to_csv('ever_green_titles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3240f569",
   "metadata": {},
   "source": [
    "## Monthly average hours viewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a98f02e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_title_hours_viewed = run_query('''\n",
    "WITH cum AS (\n",
    "            SELECT e.title_name, t.title_id, t.season_number, h.request_date, t.offering_start_date,\n",
    "            DATEDIFF('DAY', t.offering_start_date, h.request_date::DATE) as days_on_hbo_max\n",
    "            ,floor(days_on_hbo_max/7) as num_of_week\n",
    "            ,SUM(h.hours_viewed) AS daily_hours_viewed\n",
    "            FROM MAX_DEV.WORKSPACE.user_title_hours_watched_test2 h\n",
    "            JOIN (SELECT DISTINCT viewable_id, title_id, season_number, title_name FROM\n",
    "                max_dev.workspace.user_title_hours_watched_episodic_info)  e\n",
    "                on h.viewable_id = e.viewable_id\n",
    "            JOIN max_dev.workspace.user_title_hours_watched_title_series_info t\n",
    "                on e.title_id = t.title_id\n",
    "                and e.season_number = t.season_number\n",
    "            WHERE 1=1\n",
    "            AND days_on_hbo_max >= 0\n",
    "            --AND t.title_id = 'GYYxBtQFFnmbDBwEAAAAE'\n",
    "            GROUP BY 1,2,3,4,5,6\n",
    ")\n",
    "\n",
    "SELECT c.title_name, c.title_id, c.season_number, c.offering_start_date, start_date, end_date, num_of_week,\n",
    "SUM(daily_hours_viewed) AS monthly_hours_viewed, monthly_hours_viewed/subs AS monthly_average_hours_viewed\n",
    "FROM cum c\n",
    "JOIN max_dev.workspace.user_title_hours_watched_subs s\n",
    "    on DATEADD('WEEK', num_of_week, offering_start_date) = s.start_date\n",
    "and s.days_on_hbo_max = 7\n",
    "GROUP BY 1,2,3,4,5,6,7,subs \n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94b7bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_data = monthly_title_hours_viewed[['title_name', 'title_id', 'season_number', 'num_of_week', 'monthly_hours_viewed', 'monthly_average_hours_viewed']].merge(\n",
    "       title_series_info, on = ['title_id', 'season_number'])\n",
    "monthly_data['days_on_hbo_max'] = monthly_data['num_of_week']*7+7\n",
    "# data = data[data['days_on_hbo_max'] == 60]\n",
    "monthly_data['monthly_hours_viewed'] = monthly_data['monthly_hours_viewed']/monthly_data['asset_run_time_hours']\n",
    "monthly_data['monthly_average_hours_viewed'] = monthly_data['monthly_average_hours_viewed']/monthly_data['asset_run_time_hours']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd8ca858",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_data = monthly_data.sort_values(by = ['title_id', 'season_number', 'num_of_week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18300a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_data['title_season_name'] = monthly_data['title_name']\n",
    "monthly_data.loc[monthly_data['season_number']>0, 'title_season_name'] = monthly_data['title_name'] + ' S' + monthly_data['season_number'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58fa0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_data['match_id'] = monthly_data['title_id']\n",
    "monthly_data.loc[monthly_data['season_number']>0, 'match_id'] = monthly_data['title_id'] + ' S' + monthly_data['season_number'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a6a441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ever_green_titles = pd.read_csv('ever_green_titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e42e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cda4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(ever_green_titles.title_id.unique())\n",
    "fig, ax = plt.subplots(n,1,figsize=(8, 100))\n",
    "title_list = ever_green_titles.title_id.unique()\n",
    "\n",
    "for i in range(0, n, 1):\n",
    "    title_id = title_list[i]\n",
    "    plot_df = monthly_data[monthly_data['title_id'] == title_id]    \n",
    "    \n",
    "    ax1 = ax[i]\n",
    "    for t in match_id in plot_df.match_id.unique():\n",
    "        sub_plot = plot_df[plot_df['match_id'] == t]\n",
    "        title = sub_plot.title_season_name.unique()[0]\n",
    "        ax1.plot(sub_plot['days_on_hbo_max'], sub_plot['monthly_average_hours_viewed'], \n",
    "             label= title)\n",
    "\n",
    "    ax1.set_xlabel('days_on_hbo_max')\n",
    "    ax1.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3333adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a589ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
